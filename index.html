<!DOCTYPE html>
<html>

  <head>
<!--   <meta name="viewport" content="width=device-width, initial-scale=0.8"> -->
  <meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0">
  <meta charset="utf-8">
  <link href="css/bootstrap.min.css" rel="stylesheet" media="screen">
  <link href="css/bootstrap.theme.min.css" rel="stylesheet" media="screen">
  <link href="css/my-style.css" rel="stylesheet" media="screen">
  <script src="js/jquery.min.js"></script>
  <script src="js/bootstrap.min.js"></script>
  <title>Dongliang Chang</title>
</head>

  <body>
<header></header>
    <div class="container" style = "padding: 30px 1px 1px 1px;">
      <div>
<div class="row">
    <div class=" col-sm-6" align="middle">
        <img src="assets/dongliangchang_profile.jpg" class="img-responsive img-rounded" alt="Dongliang Chang" width="450">
    </div>
    <div class="col-sm-6">
        <p>
            <font size="5" color="#3367D6"><b> Dongliang Chang 常东良</b></font>
        </p>
        <p>
            Ph.D. Candidate <br>
            <a href="http://www.pris.net.cn/">PRIS lab</a> <br>
            Information and Communication Engineering <br>
            Beijing University of Posts and Telecommunications (BUPT)
        </p>
        <p>
            Email: <a href="mailto:changdongliang@bupt.edu.cn">changdongliang@bupt.edu.cn</a> <br>
            WeChat： <img src="assets/dongliangchang_wechat.jpg"  alt="Dongliang Chang" width="150"><br>
            [<a href="assets/CV.pdf">CV</a>]
            [<a href="https://scholar.google.com/citations?user=tIf50PgAAAAJ&hl=zh-CN">Google Scholar</a>]
            [<a href="https://github.com/dongliangchang">GitHub</a>]
            [<a href="https://arxiv.org/a/chang_d_1.html">ArXiv</a>]
            <!--[<a href="bio.html">Bio</a>]-->
            <br>
        </p>
    </div>
</div>
<hr>
<p>
    <font size="3">
    My primary research interests are Fine-Grained Image Analysis (FGIA) and Domain adaptation (DA). <br>
    In particular, I an interested in developing algorithms that can understand what people see and contribute to a better life. <br><br>      
    I am advised by <a href="http://www.pris.net.cn/introduction/teacher/zhanyu_ma">Prof. Zhanyu Ma</a> and
      <a href="http://personal.ee.surrey.ac.uk/Personal/Y.Song/">Prof. Yi-Zhe Song</a>.
    </font>
</p>
<p>
    <b>Keywords</b>: Fine-Grained Image Analysis, Domain Adaptation, Transfer Learning, Open Set

</p>

</div>
<hr>
<div>
  <h2>
    <font size="6" color="#3367D6">News </font>
</h2>



<div class="list-group">
    <div class="list-group-item">
        <h4  class="list-group-item-heading">Mar 2020</h4>
        <p class="list-group-item-text">Released my paper "Mind the Gap: Enlarging the Domain Gap in Open Set Domain Adaptation " on ArXiv
        [<a href="https://arxiv.org/pdf/2003.03787">paper</a>]
        [<a href="https://github.com/dongliangchang/Mutual-to-Separate/">code</a>]</a>!</p>
    </div>
    <div class="list-group-item">
        <h4  class="list-group-item-heading">Mar 2020</h4>
        <p class="list-group-item-text">Our one paper is accepted at <a href="https://www.2020.ieeeicme.org/">ICME 2020</a>!</p>
    </div>
    <div class="list-group-item">
        <h4  class="list-group-item-heading">Feb 2020</h4>
        <p class="list-group-item-text">Our one paper is accepted at <a href="https://signalprocessingsociety.org/publications-resources/ieee-transactions-image-processing">TIP 2020!</a> See <a href="https://mp.weixin.qq.com/s?__biz=MzUxMDE4MzAzOA==&mid=2247487898&idx=1&sn=cb426eeba756eee70d79a73fae902954&chksm=f907828bce700b9d7b801bfda1a3dedcbd009700eff1d27ff5e070fe9294c42c847398fffe2f&mpshare=1&scene=1&srcid=&sharer_sharetime=1585540074708&sharer_shareid=f30ede1557f44c556674cc6a85d29d3f#rd">CSIG 成果速览</a> for media coverage.</p>
    </div>

</div>

</div>
<hr>

<div>
  <h2><font size="6" color="#3367D6">Education </font></h2>
<p>
<div class="list-group">
    <div class="list-group-item">
        <p class="list-group-item-text">
<b>Beijing University of Posts and Telecommunications (BUPT)</b> (From 2019.09) <br>
<li>Ph.D. candidate of PRIS lab, BUPT <br> </li>
<li>Advisor: Prof. Zhanyu Ma <br> </li>
<br>

<b>Beijing University of Posts and Telecommunications (BUPT)</b> (2017.04-2019.09) <br>
<li>Visiting Student<br> </li>
<li>Advisor: Prof. Zhanyu Ma <br> </li>
<br>

<b>Lanzhou University of Technology (LUT)</b> (2016.09-2019.06) <br>
<li>M.E.<br> </li>
<li>Advisor: Prof. Xiaoxu Li <br> </li>
<br>

<b>Zhoukou Normal University (ZKNU)</b> (2012.09 ~ 2016.06) <br>
<li> B.E. <br> </li>
<li>Advisor: Prof. Qi Wang <br> </li>
</p>
    </div>
</div>
</p>
</div>

<hr>

<div>
  <h2>
    <font size="6" color="#3367D6">Publications </font>
</h2>


<div class="panel panel-default">
    <div class="panel-heading"><h3 class="panel-title">International Journal</h3></div>
    <ul class="list-group">
        <li class="list-group-item">
            <p id="MC-Loss">
                <b>The Devil is in the Channels: Mutual-Channel Loss for Fine-Grained Image Classification</b><br>
                <u><i>Dongliang Chang</i></u>, Yifeng Ding, Jiyang Xie, Ayan Kumar Bhunia, Xiaoxu Li, Zhanyu Ma*, Ming Wu, Jun Guo, and Yi-Zhe Song <br>
                IEEE Transactions on Image Processing 2020 <br>
                [<a href="https://ieeexplore.ieee.org/document/9005389/">paper</a>]
                [<a href="https://github.com/dongliangchang/Mutual-Channel-Loss">code</a>]
            </p>
        </li>
        <li class="list-group-item">
            <p id="Large-margin">
                <b>Large-margin Regularized Softmax Cross-Entropy Loss</b><br>
                Xiaoxu Li*, <u><i>Dongliang Chang</i></u>, Tao Tian, and Jie Cao <br>
                IEEE Access 2019 <br>
                [<a href="https://ieeexplore.ieee.org/document/8635450/">paper</a>]
            </p>
        </li>
        <li class="list-group-item">
            <p id="cmp">
                <b>Fine-Grained Vehicle Classification with Channel Max Pooling Modified CNNs</b><br>
                Zhanyu Ma*, <u><i>Dongliang Chang</i></u>, Jiyang Xie, Yifeng Ding, Shaoguo Wen, Xiao-Xu Li, Zhongwei Si, and Jun Guo <br>
                IEEE Transactions on Vehicular Technology 2019 <br>
                [<a href="https://ieeexplore.ieee.org/document/8648206/">paper</a>]
            </p>
        </li>
        <li class="list-group-item">
            <p id="dual-loss">
                <b>Dual Cross-Entropy Loss for Small-Sample Fine-Grained Vehicle Classification</b><br>
                Xiaoxu Li*, Liyun Yu, <u><i>Dongliang Chang</i></u>, Zhanyu Ma*, and Jie Cao<br>
                IEEE Transactions on Vehicular Technology 2019 <br> <br>
                [<a href="https://ieeexplore.ieee.org/document/8627964/">paper</a>]
            </p>
        </li>
        <li class="list-group-item">
            <p id="short-term">
                <b>Prediction of short-term PV power output and uncertainty analysis</b><br>
                Luyao Liu, Yi Zhao, <u><i>Dongliang Chang</i></u>, Jiyang Xie, Zhanyu Ma*, Qie Sun*, Hongyi Yin*, and Ronald Wennersten<br>
                Applied Energy 2018<br>
                [<a href="https://www.sciencedirect.com/science/article/pii/S0306261918309826/">paper</a>]
            </p>
        </li>
    </ul>
</div>

<div class="panel panel-default">
    <div class="panel-heading"><h3 class="panel-title">International Conference</h3></div>
    <ul class="list-group">
        <li class="list-group-item">
            <p id="DLChang">
                <b>IU-Module: Intersection and Union Module for Fine-Grained Visual Classification</b><br>
                Yixiao Zheng, <u><i>Dongliang Chang</i></u>, Jiyang Xie, and Zhanyu Ma* <br>
                IEEE International Conference on Multimedia and Expo (ICME), 2020 <br>
            </p>
        </li>
        <li class="list-group-item">
            <p id="DLChang">
                <b>FICAL: Focal Inter-Class Angular Loss for Image Classification</b><br>
                Xinran Wei, <u><i>Dongliang Chang</i></u>, Jiyang Xie, Yixiao Zheng, Chen Gong, Chuang Zhang, and Zhanyu Ma <br>
                IEEE International Conference on Visual Communications and Image Processing (VCIP), 2019 <br>
                [<a href="https://ieeexplore.ieee.org/abstract/document/8965889/">paper</a>]
            </p>
        </li>
        <li class="list-group-item">
            <p id="DLChang">
                <b>Channel Max Pooling for Image Classification</b><br>
                Lu Cheng, <u><i>Dongliang Chang*</i></u>, Jiyang Xie, Rongliang Ma, Chunsheng Wu, and Zhanyu Ma <br>
                International Conference on Intelligence Science and Big Data Engineering (IScIDE), 2019 <br>
                [<a href="https://link.springer.com/chapter/10.1007/978-3-030-36189-1_23">paper</a>]
            </p>
        </li>
        <li class="list-group-item">
            <p id="DLChang">
                <b>Dynamic Attention Loss for Small-sample Image Classification</b><br>
                Jie Cao, Yinping Qiu, <u><i>Dongliang Chang</i></u>, Xiaoxu Li*, and Zhanyu Ma* <br>
                The 11th Annual Conference Organized by Asia-Pacific Signal and Information Processing Association (APSIPA), 2019 <br>
                [<a href="http://www.apsipa.org/proceedings/2019/pdfs/376.pdf">paper</a>]
            </p>
        </li>
        <li class="list-group-item">
            <p id="DLChang">
                <b>Mixed Attention Mechanism for Small-Sample Fine-grained Image Classification</b><br>
                Xiaoxu Li, Jijie Wu, <u><i>Dongliang Chang</i></u>, Zhanyu Ma*, and Jie Cao* <br>
                The 11th Annual Conference Organized by Asia-Pacific Signal and Information Processing Association (APSIPA), 2019 <br>
                [<a href="http://www.apsipa.org/proceedings/2019/pdfs/378.pdf">paper</a>]
            </p>
        </li>
        <li class="list-group-item">
            <p id="DLChang">
                <b>Small-Sample Image Classification Method of Combining Prototype and Margin Learning</b><br>
                Xiaoxu Li, Liyun Yu, <u><i>Dongliang Chang</i></u>, Zhanyu Ma*, and Jie Cao* <br>
                The 11th Annual Conference Organized by Asia-Pacific Signal and Information Processing Association (APSIPA), 2019 <br>
                [<a href="http://www.apsipa.org/proceedings/2019/pdfs/383.pdf">paper</a>]
            </p>
        </li>
        <li class="list-group-item">
            <p id="DLChang">
                <b>SSE: A new selective initialization strategy for Snapshot Ensembling</b><br>
                <u><i>Dongliang Chang</i></u>, Xiaoxu Li*, Jiyang Xie, Zhanyu Ma, Jun Guo, and Jie Cao <br>
                IEEE International Conference on Cloud Computing and Intelligence Systems (CCIS), 2018 <br>
                [<a href="https://ieeexplore.ieee.org/document/8691356/">paper</a>]
            </p>
        </li>
        <li class="list-group-item">
            <p id="DLChang">
                <b>Softmax Cross Entropy Loss with Unbiased Decision Boundary for Image Classifications</b><br>
                Jie Cao*, Zhe Su, Liyun Yu, <u><i>Dongliang Chang</i></u>, Xiaoxu Li , and Zhanyu Ma <br>
                Chinese Automation Congress(CAC), 2018 <br>
                [<a href="https://ieeexplore.ieee.org/document/8623242/">paper</a>]
            </p>
    </ul>
</div>

<div class="panel panel-default">
    <div class="panel-heading"><h3 class="panel-title">Arxiv</h3></div>
    <ul class="list-group">
        <li class="list-group-item">
            <p id="DLChang">
                <b>Mind the Gap: Enlarging the Domain Gap in Open Set Domain Adaptation</b><br>
                <u><i>Dongliang Chang</i></u>, Aneeshan Sain, Zhanyu Ma, Yi-Zhe Song, Jun Guo <br>
                ArXiv 2020<br>
                [<a href="https://arxiv.org/pdf/2003.03787">paper</a>]
                [<a href="https://github.com/dongliangchang/Mutual-to-Separate/">code</a>]
            </p>
        </li>
        <li class="list-group-item">
            <p id="DLChang">
                <b>Dual-attention Guided Dropblock Module for Weakly Supervised Object Localization </b><br>
                Junhui Yin, Siqing Zhang, <u><i>Dongliang Chang</i></u>, Zhanyu Ma, Jun Guo <br>
                ArXiv 2020 <br>
                [<a href="https://arxiv.org/pdf/2003.04719/">paper</a>]
            </p>
        </li>
        <li class="list-group-item">
            <p id="DLChang">
                <b>Fine-Grained Visual Classification via Progressive Multi-Granularity Training of Jigsaw Patches </b><br>
                Ruoyi Du, <u><i>Dongliang Chang</i></u>, Ayan Kumar Bhunia, Jiyang Xie, Yi-Zhe Song, Zhanyu Ma, Jun Guo <br>
                ArXiv 2020 <br>
                [<a href="https://arxiv.org/pdf/2003.03836/">paper</a>]
                [<a href="https://github.com/RuoyiDu/PMG-Progressive-Multi-Granularity-Training">code</a>]
            </p>
        </li>
        <li class="list-group-item">
            <p id="DLChang">
                <b>Channel Attention with Embedding Gaussian Process: A Probabilistic Methodology n</b><br>
                Jiyang Xie, <u><i>Dongliang Chang</i></u>, Zhanyu Ma, Guoqiang Zhang, Jun Guoo<br>
                ArXiv 2020 <br> 
                [<a href="https://arxiv.org/pdf/2003.04575/">paper</a>]
            </p>
        </li>
        <li class="list-group-item">
            <p id="DLChang">
                <b>Weakly Supervised Attention Pyramid Convolutional Neural Network for Fine-Grained Visual Classification </b><br>
                Yifeng Ding, Shaoguo Wen, Jiyang Xie, <u><i>Dongliang Chang</i></u>, Zhanyu Ma, Zhongwei Si, Haibin Lingn<br>
                ArXiv 2020<br>
                [<a href="https://arxiv.org/pdf/2002.03353/">paper</a>]
                [<a href="http://dwz1.cc/ci8so8a">code</a>]
            </p>
        </li>
        <li class="list-group-item">
            <p id="DLChang">
                <b>Competing Ratio Loss for Discriminative Multi-class Image Classification  </b><br>
                Ke Zhang, Xinsheng Wang, Yurong Guo, <u><i>Dongliang Chang</i></u>, Zhenbing Zhao, Zhanyu Ma, Tony X.Han<br>
                ArXiv 2019<br>
                [<a href="https://arxiv.org/pdf/1912.11642/">paper</a>]
            </p>
        </li>
    </ul>
</div>

<i>* denotes corresponding author.</i>

</div>

<hr>

<div>
  <h2> <font size="6" color="#3367D6">Dataset </font></h2>
<p>
<div class="list-group">
    <div class="list-group-item">
        <p class="list-group-item-text">
<b>Overview</b><br>
<b>EEG-Database</b> involves three parts: 1) individual behavior data; 2) individual EEG data; 3) image-sketch-text data. Individual behavior data and individual EEG data are collected from the experiments on 24 subjects. Image-sketch-text data contains 1120 image-sketch-text pairs, which are split into 4 parts randomly. More details can be found in the README of EEG-Database.<br>
<img src="http://dlchang.sc2yun.com/wp-content/uploads/2020/01/dataset.png" class="img-responsive img-rounded" alt="Dataset" width="600">
<b>Download</b><br>
All data can be downloaded [<a href="https://pan.baidu.com/s/1XBNlpD4KnJ5056aBEYz6VQ">here</a>]. (passwd: nd0w)
</p>
    </div>
</div>
</p>
</div>

<hr>


<hr>

<div>
  <h2> <font size="6" color="#3367D6">Awards Scholarships </font></h2>
<p>
<div class="list-group">
    <div class="list-group-item">
        <p class="list-group-item-text">
BUPT Outstanding Doctoral Student Reserve Scholarship (2019) <br>
</p>
    </div>
</div>
</p>
</div>
 
<div>
  <h2><font size="6" color="#3367D6">Services</font></h2>
<p>
<div class="list-group">
    <div class="list-group-item">
        <p class="list-group-item-text">
Reviewer: IEEE Transactions on Vehicular Technology 2019, 2020<br>
</p>
    </div>
</div>
</p>
</div>

<hr>

<!--<div>-->
<!--  <h2>Personal</h2>-->
<!--<p>-->
<!--I enjoy playing soccer and taking a walk listening to music.-->
<!--</p>-->
<!--</div>-->


    </div>

    <footer></footer>

  </body>

</html>
